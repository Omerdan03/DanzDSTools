{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model selection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6zqGb1Wt1RO"
      },
      "source": [
        "# cross validation k-Fold\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "reg = LogisticRegression()\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    X_train2, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    y_train2, val = y[train_index], y[val_index]\n",
        "    \n",
        "final_score = cross_val_score(reg, X_train, y_train, cv= kf, scoring=\"accuracy\")\n",
        "print(f'Scores for each fold: {final_score}')\n",
        "print('Final Model Score: %.2f' %(final_score.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysfDENC1t-tb"
      },
      "source": [
        "# grid search CV\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "params_dict = {'n_estimators': [50, 100, 150],\n",
        "               'criterion': [\"gini\", \"entropy\"],\n",
        "               'max_depth': [None, 50, 100]}\n",
        "\n",
        "print(f'{type(reg).__name__} Tuning hyper-parameters with grid')\n",
        "\n",
        "ss_cv = ShuffleSplit(n_splits=5)\n",
        "\n",
        "clf_forest = GridSearchCV(cls, params_dict, cv = ss_cv, verbose=10, n_jobs=-1)\n",
        "\n",
        "clf_forest.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters set found on validation set:\")\n",
        "print(clf_forest.best_params_, '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpA-jg9ruBWl"
      },
      "source": [
        "# Random search CV\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "params_dict = {'n_estimators': [50, 100, 150],\n",
        "               'criterion': [\"gini\", \"entropy\"],\n",
        "               'max_depth': [None, 50, 100]}\n",
        "\n",
        "print(f'{type(clf).__name__} Tuning hyper-parameters with grid')\n",
        "\n",
        "ss_cv = ShuffleSplit(n_splits=5)\n",
        "\n",
        "clf_forest = RandomizedSearchCV(clf, params_dict, random_state=42, \n",
        "                                cv = ss_cv, verbose=10, n_iter=200, n_jobs=-1)\n",
        "\n",
        "clf_forest.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters set found on validation set:\")\n",
        "print(clf_forest.best_params_, '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CZu6F3g76wv"
      },
      "source": [
        "# Pipeline\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "steps = []\n",
        "steps.append(('scaler', StandardScaler()))\n",
        "steps.append(('clf', LinearSVC()))\n",
        "\n",
        "pipeline = Pipeline(steps=steps)\n",
        "\n",
        "pipeline.fit(X_train, y_train);\n",
        "preds = pipeline.predict(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUVHQam68GaR"
      },
      "source": [
        "# CV pipeline\n",
        "\n",
        "param_grid = {\n",
        "    'clf__C': np.logspace(1, 3, num=10),\n",
        "    'clf__class_weight': [None, 'balanced']\n",
        "}\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "def cv_fit_pipeline(X_train, y_train, pipeline, param_grid):\n",
        "    gs = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='f1',\n",
        "                  cv=3, n_jobs=-1, verbose=10)\n",
        "    gs_results = gs.fit(X_train, y_train)\n",
        "    return gs_results\n",
        "\n",
        "\n",
        "gs_results = cv_fit_pipeline(X_train, y_train, pipeline, param_grid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hubP_075790Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}